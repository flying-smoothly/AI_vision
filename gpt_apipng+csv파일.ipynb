{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18fIWo7OxDM0i8mgnAF0spNaQgKgJk_NM",
      "authorship_tag": "ABX9TyMIqavvrj1Idw0GY96VLzlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flying-smoothly/AI_vision/blob/master/gpt_apipng%2Bcsv%ED%8C%8C%EC%9D%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall openai"
      ],
      "metadata": {
        "id": "w9fBK4tfonLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9711587-4509-4056-e6d9-fb77cef24851"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "qJfvECCpoqGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a056a9-eaa4-4b7d-8329-33c44b038df6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.37.2-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.1/337.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "A7lBd9ALos-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b13e9a-33fe-4653-a7c5-587c6f4bed29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python\n",
        "pip install opencv-python-headless"
      ],
      "metadata": {
        "id": "CH_HmZqMiq8q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "27edb417-53e5-4481-eb80-8f606057b281"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-75d6990a88f1>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-75d6990a88f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install opencv-python\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "9zASAvFjovPS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCclAMKheboT",
        "outputId": "32370a07-b6c9-46c6-9be2-3af802193793"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv('/content/drive/MyDrive/key.env')\n",
        "\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY') #os 모듈을 사용하여 환경 변수에서 API 키를 불러옵니다.\n",
        "\n",
        "if openai.api_key:\n",
        "    print(\"API 키가 성공적으로 설정되었습니다.\")\n",
        "else:\n",
        "    print(\"API 키를 설정하는 데 실패했습니다.\")\n",
        "\n",
        "client=OpenAI()"
      ],
      "metadata": {
        "id": "LQaUJaj9oxbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38029506-8a79-4dd1-9c7b-71ac4c545626"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 키가 성공적으로 설정되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9DTJBmN_ol4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85081265-7711-4c0b-9508-9d1b0544a49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': {'message': 'Invalid chat format. Content blocks are expected to be either text or image_url type.', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
          ]
        }
      ],
      "source": [
        "# Function to encode a file\n",
        "def encode_file(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        return base64.b64encode(file.read()).decode('utf-8')\n",
        "\n",
        "# Paths to your files\n",
        "image_path = \"/content/drive/MyDrive/depth.bag/depth_Depth_31135.png\"\n",
        "csv1_path = \"/content/drive/MyDrive/depth.bag/depth_Depth_31135_metadata.csv\"\n",
        "csv2_path = \"/content/drive/MyDrive/depth.bag/spray_depth_metrics.csv\"\n",
        "\n",
        "# Encoding the files\n",
        "base64_image = encode_file(image_path)\n",
        "base64_csv1 = encode_file(csv1_path)\n",
        "base64_csv2 = encode_file(csv2_path)\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"gpt-4o\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"PNG 파일에 depth camera로 찍은 이미지의 깊이 정보와 RGB 정보가 저장되어 있어. 이미지는 스프레이를 찍은 거고 나는 스프레이의 깊이 정보를 알고 싶어. 스프레이가 카메라로부터 얼마나 떨어져 있었는지 png 파일을 읽어서 말해줄 수 있어? 얼마나 떨어져 있는지만 말해주면 돼.\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"file\",\n",
        "                    \"file\": {\n",
        "                        \"filename\": \"depth_Depth_31135_metadata.csv\",\n",
        "                        \"filetype\": \"csv\",\n",
        "                        \"content\": base64_csv1\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"file\",\n",
        "                    \"file\": {\n",
        "                        \"filename\": \"spray_depth_metrics.csv\",\n",
        "                        \"filetype\": \"csv\",\n",
        "                        \"content\": base64_csv2\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 300\n",
        "}\n",
        "\n",
        "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Function to encode a file\n",
        "def encode_file(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        return base64.b64encode(file.read()).decode('utf-8')\n",
        "\n",
        "# Paths to your files\n",
        "image_path = \"/content/drive/MyDrive/depth.bag/depth_Depth_31135.png\"\n",
        "csv1_path = \"/content/drive/MyDrive/depth.bag/depth_Depth_31135_metadata.csv\"\n",
        "csv2_path = \"/content/drive/MyDrive/depth.bag/spray_depth_metrics.csv\"\n",
        "\n",
        "# Encoding the files\n",
        "base64_image = encode_file(image_path)\n",
        "base64_csv1 = encode_file(csv1_path)\n",
        "base64_csv2 = encode_file(csv2_path)\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"gpt-4o\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"\"\"\"Can you tell me the location of the cat on the image, very accurately, ensuring that the area covers the entire object (cat).\n",
        "                    Share the x_min, y_min, x_max, y_max in 0-1 normalized space. Only return the numbers, nothing else. Calculate the pixel values from the normalized values. The total width is 424 and the total height is 240.\n",
        "                    Then, using the calculated pixel coordinates, detect the object within the image with a bounding box.\" png,csv 파일에 depth camera로 찍은 이미지의 깊이 정보와 RGB 정보가 저장되어 있어. 이미지는 스프레이를 찍은 거고 나는 스프레이의 깊이 정보를 알고 싶어.\n",
        "                    스프레이가 카메라로부터 얼마나 떨어져 있었는지 png, csv 파일을 읽어서 말해줄 수 있어? 얼마나 떨어져 있는지만 말해주면 돼.\"\"\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": f\"첫 번째 CSV 파일 (depth_Depth_31135_metadata.csv) 내용:\\n{base64_csv1}\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": f\"두 번째 CSV 파일 (spray_depth_metrics.csv) 내용:\\n{base64_csv2}\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"max_tokens\": 400\n",
        "}\n",
        "\n",
        "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "# Parse the JSON response\n",
        "response_json = response.json()\n",
        "\n",
        "# Extract the 'content' value\n",
        "content = response_json['choices'][0]['message']['content']\n",
        "\n",
        "# Print the 'content' value\n",
        "print(content)\n",
        "\n",
        "# If the response is incomplete, continue the conversation to get more information\n",
        "while response_json['choices'][0]['finish_reason'] == 'length':\n",
        "    payload['messages'].append({\"role\": \"assistant\", \"content\": content})\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "    response_json = response.json()\n",
        "    content = response_json['choices'][0]['message']['content']\n",
        "    print(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OTTVePPI1591",
        "outputId": "26f079ad-cbff-4196-e7f9-f03d33e3a59d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제시하신 데이터를 바탕으로 깊이 정보를 분석해 보았습니다. 그러나 텍스트 형태의 CSV 파일을 통해서는 깊이 이미지 내 특정 객체(예: 스프레이)의 위치 정보를 직접적으로 식별하고 계산하기 어려울 수 있습니다. \n",
            "\n",
            "일반적으로 RGB와 깊이 정보를 저장하고 있는 이미지를 나타낸 후, 깊이 값(단위: mm 또는 m)을 통해 특정 객체의 거리를 찾아내려면 이미지 분석 및 객체 식별 과정을 거쳐야 합니다. 이 과정에서는 특정 객체를 인식한 후, 해당 객체의 평균 깊이를 계산하게 됩니다.\n",
            "\n",
            "제공된 이미지를 분석해본 결과, 빨간색에서 파란색으로의 그라데이션이 깊이 정보를 나타내는 것 같습니다. 검정색은 데이터가 없거나 노이즈로 인해 깊이 정보를 얻을 수 없는 부분일 수 있습니다. \n",
            "\n",
            "스프레이의 정확한 포지션을 정의하고 나서, 해당 부분의 평균 깊이 정보를 이용해 카메라로부터의 거리를 산출해야 합니다.\n",
            "\n",
            "**CSV 파일 예시:**\n",
            "```csv\n",
            "디바이스 정보:\n",
            "유형: 이어링모델X\n",
            "HW ID: 0B07\n",
            "시리얼 넘버: 1366220739800\n",
            "펌웨어 버전: 5.16.0.1\n",
            "스트리밍 프로파일:\n",
            "스트림 | 포맷 | 해상도 | FPS\n",
            "깊이 | Z16 | 848x480 | 30\n",
            "인프라레드 1 | Y8 | 848x480 | 30\n",
            "\n",
            "환경:\n",
            "평면 적합 거리(mm), N/A\n",
            "지면-진실 거리(mm), N/A\n",
            "\n",
            "샘플 ID, 프레임 #, 타임스탬프 (ms), 필 레이트 %, z 정확도 %, 평면 적합 RMS 오류 %, 서브픽셀 RMS 오류\n",
            "이미지를 통해 스프레이의 깊이 정보를 분석하려면, 깊이 이미지의 특정 좌표에서의 값을 추출해야 합니다. 그러나 현재 주어진 데이터는 전체 이미지를 기반으로 한 것으로, 특정 객체에 대해 이야기를 하려면 상세한 이미지 좌표나 추가 정보를 통해 객체 위치를 도출해야 합니다. 즉, 아래의 과정이 필요할 것입니다.\n",
            "\n",
            "1. **이미지 분석을 통한 객체 위치 추출**:\n",
            "   - 스프레이 위치를 특정할 수 있다면, 해당 좌표의 깊이 값을 직접 확인할 수 있습니다.\n",
            "   \n",
            "2. **깊이 데이터를 좌표별로 분석**:\n",
            "   - 깊이 이미지는 각 픽셀이 카메라로부터의 거리를 RGB 값으로 표시합니다. 예를 들어, 밝은 색상일수록 가까이, 어두운 색상일수록 멀리 있는 것을 나타낼 수 있습니다.\n",
            "\n",
            "제공된 이미지를 보면 특정 영역이 매우 다양한 색상 값을 가지고 있으며, 이는 다양한 깊이를 나타냅니다. 아래에 해당 이미지를 분석하여 깊이 값을 추출하는 절차를 설명합니다.\n",
            "\n",
            "### 예시: 깊이 이미지 분석 절차\n",
            "1. **이미지 로드 및 시각화**:\n",
            "   - 제공된 깊이 이미지를 로드하고 시각화합니다.\n",
            "\n",
            "2. **객체 위치 추출**:\n",
            "   - 스프레이의 경계를 추출합니다.\n",
            "   - 적절한 좌표를 통해 해당 영역의 평균 깊이를 산출합니다.\n",
            "\n",
            "3. **깊이 값 추출**:\n",
            "   - 추출된 좌표의 깊이 값을 계산하고, 이를 기반으로 카메라로부터의 거리를 도출합니다.\n",
            "\n",
            "### 예시 코드 (Python + OpenCV):\n",
            "```python\n",
            "import cv2\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# 이미지 로드\n",
            "depth_image = cv2.imread('depth_image.png',\n",
            "```python\n",
            "import cv2\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# 이미지 로드\n",
            "depth_image = cv2.imread('depth_image.png', cv2.IMREAD_UNCHANGED)\n",
            "\n",
            "# 이미지 시각화\n",
            "plt.imshow(depth_image, cmap='viridis')\n",
            "plt.colorbar()\n",
            "plt.show()\n",
            "\n",
            "# 스프레이 영역 지정 (예시로 임의의 좌표 사용)\n",
            "# 좌표는 실제 상황에서는 객체 인식을 통해 결정하여야 합니다.\n",
            "# 예를 들어, 스프레이가 이미지 중앙에 있다고 가정\n",
            "height, width = depth_image.shape[:2]\n",
            "spray_x_start = width // 3\n",
            "spray_x_end = 2 * width // 3\n",
            "spray_y_start = height // 3\n",
            "spray_y_end = 2 * height // 3\n",
            "\n",
            "# 스프레이 영역의 깊이 값 추출\n",
            "spray_region = depth_image[spray_y_start:spray_y_end, spray_x_start:spray_x_end]\n",
            "\n",
            "# 스프레이 영역의 평균 깊이 계산\n",
            "average_depth = np.mean(spray_region)\n",
            "\n",
            "print(f\"스프레이의 평균 깊이: {average_depth:.2f} 단위 (예: mm 또는 cm)\")\n",
            "```\n",
            "\n",
            "이 예시 코드는 다음과 같은 방법으로 동작합니다:\n",
            "1. `depth_image.png` 파일을 이미지 데이터로 로드합니다.\n",
            "2. 이미지를 시각화하여 깊이 데이터를 확인합니다.\n",
            "3. 스프레이의 위치를 임의로 설정합니다. 실제로는 객체 인식 기법을 사용하여 스프레이 위치를 찾아야 합니다.\n",
            "4. 해당 영역의 깊이 값을 추출하고, 평균 깊이를 계산합니다.\n",
            "\n",
            "위 코드에서 출력되는 값인 `average_depth`는 스프레이가 카메라로부터 얼마나 떨어져 있는지를 나타냅니다. 깊이 데이터의 단위는 센티미터(cm)나 밀리미터(mm)\n",
            "수를 사용합니다. 단위는 깊이 카메라의 설정에 따라 달라질 수 있습니다. 위의 코드는 예시로 스프레이가 이미지의 중앙에 있다고 가정했지만, 실제 데이터에서 정확한 스프레이 위치를 찾아야 합니다. 이를 위해서는 객체 인식 기술을 활용하는 것이 추천됩니다.\n",
            "\n",
            "```python\n",
            "import cv2\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# 이미지 로드\n",
            "depth_image = cv2.imread('depth_image.png', cv2.IMREAD_UNCHANGED)\n",
            "\n",
            "# 이미지 시각화\n",
            "plt.imshow(depth_image, cmap='viridis')\n",
            "plt.colorbar()\n",
            "plt.show()\n",
            "\n",
            "# 스프레이 영역 지정 (예시로 임의의 좌표 사용)\n",
            "# 좌표는 실제 상황에서는 객체 인식을 통해 결정하여야 합니다.\n",
            "# 예를 들어, 스프레이가 이미지 중앙에 있다고 가정\n",
            "height, width = depth_image.shape[:2]\n",
            "spray_x_start = width // 3\n",
            "spray_x_end = 2 * width // 3\n",
            "spray_y_start = height // 3\n",
            "spray_y_end = 2 * height // 3\n",
            "\n",
            "# 스프레이 영역의 깊이 값 추출\n",
            "spray_region = depth_image[spray_y_start:spray_y_end, spray_x_start:spray_x_end]\n",
            "\n",
            "# 스프레이 영역의 평균 깊이 계산\n",
            "average_depth = np.mean(spray_region)\n",
            "\n",
            "print(f\"스프레이의 평균 깊이: {average_depth:.2f} 단위 (예: mm 또는 cm)\")\n",
            "```\n",
            "\n",
            "위 코드의 `average_depth`는 스프레이의 실제 거리를 나타냅니다. 실제 데이터 처리에서는 신뢰도 및 노이즈 감소를 위해 안정화 및 정제(예: 깊이 데이터 필터링)를 거치는 것이 필요합니다. 따라서 이를 바탕으로 정확한 계산을 위해 추가적인 전처리 단계가 필요할 수 있습니다\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-debfca72f72c>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'finish_reason'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://api.openai.com/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "##               Read bag from file                ##\n",
        "#####################################################\n",
        "\n",
        "\n",
        "# First import library\n",
        "import pyrealsense2 as rs\n",
        "# Import Numpy for easy array manipulation\n",
        "import numpy as np\n",
        "# Import OpenCV for easy image rendering\n",
        "import cv2\n",
        "# Import argparse for command-line options\n",
        "import argparse\n",
        "# Import os.path for file path manipulation\n",
        "import os.path\n",
        "\n",
        "# Create object for parsing command-line options\n",
        "parser = argparse.ArgumentParser(description=\"Read recorded bag file and display depth stream in jet colormap.\\\n",
        "                                Remember to change the stream fps and format to match the recorded.\")\n",
        "# Add argument which takes path to a bag file as an input\n",
        "parser.add_argument(\"-i\", \"--input\", type=str, help=\"Path to the bag file\")\n",
        "# Parse the command line arguments to an object\n",
        "args = parser.parse_args()\n",
        "# Safety if no parameter have been given\n",
        "if not args.input:\n",
        "    print(\"No input paramater have been given.\")\n",
        "    print(\"For help type --help\")\n",
        "    exit()\n",
        "# Check if the given file have bag extension\n",
        "if os.path.splitext(args.input)[1] != \".bag\":\n",
        "    print(\"The given file is not of correct file format.\")\n",
        "    print(\"Only .bag files are accepted\")\n",
        "    exit()\n",
        "try:\n",
        "    # Create pipeline\n",
        "    pipeline = rs.pipeline()\n",
        "\n",
        "    # Create a config object\n",
        "    config = rs.config()\n",
        "\n",
        "    # Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
        "    rs.config.enable_device_from_file(config, args.input)\n",
        "\n",
        "    # Configure the pipeline to stream the depth stream\n",
        "    # Change this parameters according to the recorded bag file resolution\n",
        "    config.enable_stream(rs.stream.depth, rs.format.z16, 30)\n",
        "\n",
        "    # Start streaming from file\n",
        "    pipeline.start(config)\n",
        "\n",
        "    # Create opencv window to render image in\n",
        "    cv2.namedWindow(\"Depth Stream\", cv2.WINDOW_AUTOSIZE)\n",
        "\n",
        "    # Create colorizer object\n",
        "    colorizer = rs.colorizer()\n",
        "\n",
        "    # Streaming loop\n",
        "    while True:\n",
        "        # Get frameset of depth\n",
        "        frames = pipeline.wait_for_frames()\n",
        "\n",
        "        # Get depth frame\n",
        "        depth_frame = frames.get_depth_frame()\n",
        "\n",
        "        # Colorize depth frame to jet colormap\n",
        "        depth_color_frame = colorizer.colorize(depth_frame)\n",
        "\n",
        "        # Convert depth_frame to numpy array to render image in opencv\n",
        "        depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
        "\n",
        "        # Render image in opencv window\n",
        "        cv2.imshow(\"Depth Stream\", depth_color_image)\n",
        "        key = cv2.waitKey(1)\n",
        "        # if pressed escape exit program\n",
        "        if key == 27:\n",
        "            cv2.destroyAllWindows()\n",
        "            break"
      ],
      "metadata": {
        "id": "naqQoGPBqJ8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 이미지 읽기\n",
        "image_path = '/content/drive/MyDrive/LLM/cat6.jpeg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# 이미지가 제대로 로드되었는지 확인\n",
        "if image is None:\n",
        "    print(\"Error: Unable to load image. Please check the file path.\")\n",
        "else:\n",
        "    # 예시로 설정한 컵과 손의 바운딩 박스 좌표 (직접 정의 필요)\n",
        "    cat_box = (96, 90, 247, 426)  # 고양이 바운딩 박스 좌표\n",
        "    #hand_box = (830, 700, 960, 820)  # 손 바운딩 박스 좌표\n",
        "\n",
        "    # 바운딩 박스 그리기\n",
        "    cv2.rectangle(image, (cat_box[0], cat_box[1]), (cat_box[2], cat_box[3]), (0, 255, 0), 2)\n",
        "    #cv2.rectangle(image, (hand_box[0], hand_box[1]), (hand_box[2], hand_box[3]), (255, 0, 0), 2)\n",
        "\n",
        "    # 결과 이미지 보여주기\n",
        "    cv2_imshow(image)"
      ],
      "metadata": {
        "id": "BecNJwcxe3CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 읽어옵니다\n",
        "image_path = '/content/drive/MyDrive/LLM/cat1.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# 이미지가 제대로 로드되었는지 확인합니다\n",
        "if image is None:\n",
        "    raise ValueError(f\"이미지를 로드할 수 없습니다: {image_path}\")\n",
        "\n",
        "# 이미지를 그레이스케일로 변환합니다\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 노이즈 제거를 위해 Gaussian 블러링을 적용합니다\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# 이진화하여 컵을 추출합니다\n",
        "_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "# 모폴로지 연산을 사용하여 객체를 확장합니다\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "morphed = cv2.dilate(thresh, kernel, iterations=2)\n",
        "\n",
        "# 외곽선을 찾습니다\n",
        "contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# 각 외곽선을 감싸는 직사각형을 계산하고 이미지에 그립니다\n",
        "for i, contour in enumerate(contours):\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "    # 필터링 조건: 특정 크기 이상의 컨투어만 처리합니다\n",
        "    if w > 50 and h > 50:\n",
        "        # 바운딩 박스를 약간 확장합니다\n",
        "        padding = 10\n",
        "        x, y, w, h = x - padding, y - padding, w + 2 * padding, h + 2 * padding\n",
        "\n",
        "        # 정규화된 좌표 출력\n",
        "        print(f\"Cup {i+1}:\")\n",
        "        print(f\"Top-left: ({x}, {y})\")\n",
        "        print(f\"Top-right: ({x+w}, {y})\")\n",
        "        print(f\"Bottom-left: ({x}, {y + h})\")\n",
        "        print(f\"Bottom-right: ({x + w}, {y + h})\")\n",
        "        print()\n",
        "\n",
        "        # 원본 이미지에 사각형 그리기\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "# 이미지를 출력합니다\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')  # 축을 끕니다\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DkeXNNTi3Tk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}